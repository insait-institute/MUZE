{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2472, 0.6547, 0.7341, 0.4455],\n",
      "        [0.0959, 0.3835, 0.9753, 0.9571],\n",
      "        [0.3276, 0.6565, 0.8749, 0.1919],\n",
      "        [0.7725, 0.8318, 0.8900, 0.7010],\n",
      "        [0.9623, 0.7471, 0.1597, 0.3891]])\n"
     ]
    }
   ],
   "source": [
    "scores = torch.rand(5,4)\n",
    "targets=torch.rand(5,4)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_per_class2(scores, targets:torch.Tensor):\n",
    "    ap = torch.zeros(scores.size(1))\n",
    "    rg = torch.arange(1, scores.size(0) + 1).float()\n",
    "    # compute average precision for each class\n",
    "    batch_sz=2\n",
    "    for k in range((scores.size(1)-1)//batch_sz+1):\n",
    "        # sort scores\n",
    "        scores_k = scores[:, k*batch_sz:(k+1)*batch_sz]\n",
    "        targets_k = targets[:, k*batch_sz:(k+1)*batch_sz]\n",
    "        _, sortind = torch.sort(scores_k, 0, True)\n",
    "        sortcol = torch.arange(0,sortind.shape[1]).repeat(sortind.shape[0],1)\n",
    "        print(_)\n",
    "        print(sortind)\n",
    "        print(sortcol)\n",
    "        print(sortind.shape)\n",
    "        truth = targets_k[sortind,sortcol]\n",
    "        score_truth = scores_k[sortind,sortcol]\n",
    "        # print(score_truth)\n",
    "        # print('')\n",
    "        tp = truth.float().cumsum(1)\n",
    "        # compute precision curve\n",
    "        # print(truth.shape)\n",
    "        # print(tp.shape)\n",
    "        # print(rg.shape)\n",
    "        # break\n",
    "        precision = tp.div(rg.unsqueeze(1))\n",
    "        # compute average precision\n",
    "        ap[k*batch_sz:(k+1)*batch_sz] = precision[truth.bool()].sum(0) / max(float(truth.sum()), 1)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_precision_per_class2(scores,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_per_class(scores, targets):\n",
    "    ap = torch.zeros(scores.size(1))\n",
    "    rg = torch.arange(1, scores.size(0) + 1).float()\n",
    "    # compute average precision for each class\n",
    "    for k in range(scores.size(1)):\n",
    "        # sort scores\n",
    "        scores_k = scores[:, k]\n",
    "        targets_k = targets[:, k]\n",
    "        _, sortind = torch.sort(scores_k, 0, True)\n",
    "        truth = targets_k[sortind]\n",
    "        tp = truth.float().cumsum(0)\n",
    "        # compute precision curve\n",
    "        precision = tp.div(rg)\n",
    "        # compute average precision\n",
    "        ap[k] = precision[truth.bool()].sum() / max(float(truth.sum()), 1)\n",
    "        print(\"truth\",truth,tp)\n",
    "        print(\"ap\",ap,precision[truth.bool()],max(float(truth.sum()), 1))\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_per_class2(scores, targets:torch.Tensor):\n",
    "    ap = torch.zeros(scores.size(1))\n",
    "    rg = torch.arange(1, scores.size(0) + 1).float()\n",
    "    # compute average precision for each class\n",
    "    batch_sz=2\n",
    "    for k in range((scores.size(1)-1)//batch_sz+1):\n",
    "        # sort scores\n",
    "        scores_k = scores[:, k*batch_sz:(k+1)*batch_sz]\n",
    "        targets_k = targets[:, k*batch_sz:(k+1)*batch_sz]\n",
    "        _, sortind = torch.sort(scores_k, 0, True)\n",
    "        sortcol = torch.arange(0,sortind.shape[1]).repeat(sortind.shape[0],1)\n",
    "        truth = targets_k[sortind,sortcol]\n",
    "        tp = truth.float().cumsum(0)\n",
    "        # compute precision curve\n",
    "        precision = tp.div(rg.unsqueeze(1))\n",
    "        # compute average precision\n",
    "        ap[k*batch_sz:(k+1)*batch_sz] = precision[truth.bool()].view_as(truth).sum(0) / torch.clip((truth.sum(0)), min=1)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth tensor([0.3651, 0.0983, 0.8205, 0.0642, 0.4067]) tensor([0.3651, 0.4634, 1.2839, 1.3481, 1.7548])\n",
      "ap tensor([0.9760, 0.0000, 0.0000, 0.0000]) tensor([0.3651, 0.2317, 0.4280, 0.3370, 0.3510]) 1.7548457384109497\n",
      "truth tensor([0.1815, 0.6678, 0.8743, 0.6479, 0.0786]) tensor([0.1815, 0.8493, 1.7236, 2.3716, 2.4501])\n",
      "ap tensor([0.9760, 0.9239, 0.0000, 0.0000]) tensor([0.1815, 0.4247, 0.5745, 0.5929, 0.4900]) 2.4501490592956543\n",
      "truth tensor([0.1016, 0.0624, 0.7112, 0.4481, 0.0738]) tensor([0.1016, 0.1639, 0.8752, 1.3233, 1.3970])\n",
      "ap tensor([0.9760, 0.9239, 0.7770, 0.0000]) tensor([0.1016, 0.0820, 0.2917, 0.3308, 0.2794]) 1.3970437049865723\n",
      "truth tensor([0.7820, 0.8700, 0.1454, 0.5552, 0.2111]) tensor([0.7820, 1.6520, 1.7973, 2.3525, 2.5636])\n",
      "ap tensor([0.9760, 0.9239, 0.7770, 1.2904]) tensor([0.7820, 0.8260, 0.5991, 0.5881, 0.5127]) 2.5635673999786377\n",
      "correct tensor([0.9760, 0.9239, 0.7770, 1.2904])\n",
      "------------------------------\n",
      "ap tensor([0.9760, 0.9239, 0.0000, 0.0000]) tensor([[0.3651, 0.1815],\n",
      "        [0.2317, 0.4247],\n",
      "        [0.4280, 0.5745],\n",
      "        [0.3370, 0.5929],\n",
      "        [0.3510, 0.4900]]) tensor([1.7548, 2.4501])\n",
      "ap tensor([0.9760, 0.9239, 0.7770, 1.2904]) tensor([[0.1016, 0.7820],\n",
      "        [0.0820, 0.8260],\n",
      "        [0.2917, 0.5991],\n",
      "        [0.3308, 0.5881],\n",
      "        [0.2794, 0.5127]]) tensor([1.3970, 2.5636])\n",
      "mine tensor([0.9760, 0.9239, 0.7770, 1.2904])\n"
     ]
    }
   ],
   "source": [
    "print(\"correct\",average_precision_per_class(scores,targets))\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(\"mine\",average_precision_per_class2(scores,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0151, 3.8960, 2.1993, 3.9154])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy_loss(scores, targets:torch.Tensor):\n",
    "    scores=F.softmax(scores.float(), dim=0)\n",
    "    loss = 0\n",
    "    for i in range(len(scores)):\n",
    "        loss = loss + (-1 * targets[i]*np.log(scores[i]))\n",
    "    return loss\n",
    " \n",
    "\n",
    "cross_entropy_loss(scores, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
