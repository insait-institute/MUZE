{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/username/open_clip/finetuning/train12.csv\")\n",
    "df2 = pd.read_csv(\"/home/username/open_clip/finetuning/val12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_images=df[df[\"image_path\"]>=\"/scratch/username/data/va_images/\"]\n",
    "britmus_images=df[df[\"image_path\"]<\"/scratch/username/data/va_images/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# britmus_images.to_csv(\"/home/username/open_clip/finetuning/val_britmus.csv\", index=False)  \n",
    "# va_images.to_csv(\"/home/username/open_clip/finetuning/val_va.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['my_code', 'image_code', 'image_path', 'caption', 'Museum number',\n",
      "       'Subjects', 'Curators Comments', 'Inscription', 'Technique',\n",
      "       'Materials', 'Production place', 'Production date', 'Assoc name',\n",
      "       'Culture', 'Object type', 'Producer name', 'School/style', 'Title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val6 = pd.read_csv('/home/username/open_clip/finetuning/val6.csv')\n",
    "print(val6.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_categories=['Subjects', 'Inscription', 'Technique', 'Materials', 'Production place', 'Production date', \n",
    "                 'Assoc name', 'Culture', 'Object type', 'Producer name']\n",
    "new_categories=['systemNumber', 'accessionNumber', 'objectType', 'titles', 'summaryDescription', \n",
    "                 'physicalDescription', 'artistMakerPerson', 'artistMakerOrganisations', 'artistMakerPeople', \n",
    "                 'materials', 'techniques', 'materialsAndTechniques', 'categories', 'styles', 'collectionCode',\n",
    "                   'images', 'imageResolution', 'galleryLocations', 'partTypes', 'contentWarnings', 'placesOfOrigin',\n",
    "                     'productionDates', 'associatedObjects', 'creditLine', 'dimensions', 'dimensionsNote', 'marksAndInscriptions', \n",
    "                     'objectHistory', 'historicalContext', 'briefDescription', 'bibliographicReferences', 'production', 'productionType', \n",
    "                     'contentDescription', 'contentPlaces', 'associatedPlaces', 'contentPerson', 'associatedPerson', 'contentOrganisations', \n",
    "                     'associatedOrganisations', 'contentPeople', 'associatedPeople', 'contentEvents', 'associatedEvents', 'contentOthers', \n",
    "                     'contentConcepts', 'contentLiteraryRefs', 'galleryLabels', 'partNumbers', 'accessionNumberNum', 'accessionNumberPrefix', \n",
    "                     'accessionYear', 'otherNumbers', 'copyNumber', 'aspects', 'assets', 'recordModificationDate', 'recordCreationDate']\n",
    "without=['systemNumber',\"collectionCode\", 'productionType','bibliographicReferences','dimensions','dimensionsNote','creditLine',\"images\",\n",
    "          \"imageResolution\",\"galleryLocations\",'artistMakerPeople','artistMakerOrganisations','accessionNumber',\"contentWarnings\", \n",
    "          \"associatedObjects\",'contentDescription', 'contentPlaces', 'associatedPlaces', 'contentPerson', \n",
    " 'associatedPerson', 'contentOrganisations', 'associatedOrganisations', 'contentPeople', \n",
    " 'associatedPeople', 'contentEvents', 'associatedEvents', 'contentOthers', 'contentConcepts', \n",
    " 'contentLiteraryRefs', 'galleryLabels', 'partNumbers', 'accessionNumberNum', 'accessionNumberPrefix', \n",
    " 'accessionYear', 'otherNumbers', 'number','copyNumber', 'aspects',\n",
    " 'assets','recordModificationDate','recordCreationDate']\n",
    "common=['inscription', 'technique', 'materials', 'production']\n",
    "new_categories_kept=['objectType','titles','summaryDescription','physicalDescription','artistMakerPerson','materials',\n",
    "'techniques','materialsAndTechniques','categories','styles','partTypes','placesOfOrigin','productionDates','marksAndInscriptions',\n",
    "'objectHistory','historicalContext','briefDescription','production',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categories=old_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['objectType', 'titles', 'summaryDescription', 'physicalDescription', 'artistMakerPerson', 'materials', 'techniques', 'materialsAndTechniques', 'categories', 'styles', 'partTypes', 'placesOfOrigin', 'productionDates', 'marksAndInscriptions', 'objectHistory', 'historicalContext', 'briefDescription', 'production']\n",
      "['Subjects', 'Inscription', 'Technique', 'Materials', 'Production place', 'Production date', 'Assoc name', 'Culture', 'Object type', 'Producer name']\n"
     ]
    }
   ],
   "source": [
    "print(new_categories_kept)\n",
    "print(old_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiable_brit=[\"materials=multiclass\",\"technique=multiclass\",\"subjects=multiclass\"\n",
    "#                    \"production_place=multiclass\",\"production date=period\",\"culture=multiclass\",\"object_type=multiclass\"]\n",
    "\n",
    "# classifiable_va=[\"materials=?multiclass\",\"techniques=?multicls\",\"categories=multiclass\",\"styles=multiclass\",\n",
    "#                  \"artistMakerPerson?\",\"partTypes=multiclass\",\"placesOfOrigin=poss?multi\"\n",
    "#                  \"productionDates=period\"]\n",
    "classifiable_va=[\"materials\",\"techniques\",\"categories\",\"styles\"\n",
    "                 ,\"partTypes\",\"productionDates\"]\n",
    "recall_va=[\"objectType\",\"titles\",\"physical_description\",\"summaryDescription\",\"marksAndInscriptions\"\n",
    "          \"objectHistory\",\"historicalContext\",\"briefDescription\",\"production\",\"placesOfOrigin\",\"artistMakerPerson\"]\n",
    "redundant=[\"materialsAndTechniques\"]\n",
    "classifiable_brit=[\"Materials\",\"Technique\",\"Subjects\",\"School/style\"\n",
    "                   \"Production place\",\"Production date\",\"Culture\",\"Object type\"]\n",
    "recall_brit=[\"Assoc name\",\"Producer name\",\"Inscription\",\"Curators Comments\",\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "va_path=\"/home/username/open_clip/finetuning/train6.csv\"\n",
    "brit_df = pd.read_csv(va_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_path=\"/home/username/open_clip/finetuning/val6.csv\"\n",
    "brit_df2 = pd.read_csv(va_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brit_df=pd.concat([brit_df, brit_df2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "brit_df=new_brit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process(text,cls):\n",
    "    original_text=text\n",
    "    try:\n",
    "        if cls==\"Production date\":\n",
    "            text=text.lower()\n",
    "\n",
    "            if \"or\" in text and \"before\" not in text and \"historic\" not in text:\n",
    "                pos=text.index(\"or\")\n",
    "                text=text[:pos]\n",
    "\n",
    "            \n",
    "            if \"pre-historic\" in text:\n",
    "                text=\"pre-historic\"\n",
    "                set_text=set([text])\n",
    "                return set_text\n",
    "\n",
    "            for i in [\"summer\",\"winter\",\"autumn\",\"spring\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\",\"january\",\"february\",\"march\",\"april\",\"may\",\"jun\",\"jul\",\"aug\",\"sept\",\"sep\",\"oct\",\"nov\",\"jan\",\"feb\",\"mar\",\"apr\"]:\n",
    "                if i in text:\n",
    "                    try:\n",
    "                        val=int(text[-4:])\n",
    "                        text=text[-4:]\n",
    "                    except:\n",
    "                        text=\"unknown\"\n",
    "                        set_text=set([text])\n",
    "                        return set_text\n",
    "            \n",
    "            for p1,p2 in [(\"first century\",\"1st century\"),(\"second century\",\"2nd century\"),(\"third century\",\"3rd century\"),(\"forth century\",\"4th century\"),(\"fifth century\",\"5th century\"),(\"sixth century\",\"6th century\"),(\"seventh century\",\"7th century\"),(\"eighth century\",\"8th century\"),(\"ninth century\",\"9th century\"),(\"tenth century\",\"10th century\"),(\"eleventh century\",\"11th century\"),(\"twelfth century\",\"12th century\"),(\"thirteenth century\",\"13th century\"),(\"fourteenth century\",\"14th century\"),(\"fifteenth century\",\"15th century\"),(\"sixteenth century\",\"16th century\"),(\"nineteen\",\"19\"),(\"eighteen\",\"18\"),(\"seventeen\",\"17\"),(\"twentie\",\"20\")]:\n",
    "                            text=text.replace(p1,p2)\n",
    "\n",
    "            for i in [\"perhaps\",\"perhap\",\"copyright\",\"from\",\"between\",\"btwn\",\"after\",\"(chain and pendant)\",\"late ptolemaic\", \"roman periods\",\"middle\",\"possiby\",\"around\",\"centuy\",\"fourth\",\"earlier\",\"circa\",\"pre-\",\"ormoulu mounts\",\"first\", \"about\",\"2nd half\",\"lte\",\"mid.\",\"later\",\"probably\", \"before\",\"second\",\"mid-century\",\"century\",\"early\",\"mid to late\",\"late\",\"last\",\"quarter\",\"half\",\"(?)\",\"ca.\",\"mid\",\"possibly\",\"or\",\"ca\",\"of\", \"and\"]:\n",
    "                text=text.replace(i,\"\")\n",
    "            # print(text)\n",
    "                \n",
    "            if original_text==\"later \":\n",
    "                print(\"text\",text)\n",
    "            if text==\"\" or text==\" \":\n",
    "                text=\"unknown\"\n",
    "                set_text=set([text])\n",
    "                return set_text\n",
    "           \n",
    "            # print(text)\n",
    "            for p1,p2 in [(\"b.c.\",\"bc\"),(\"bc.\",\"bc\"),(\"b.c\",\"bc\"),(\"c.\",\"\"),(\"bce\",\"bc\"),(\"ce\",\"\")]:\n",
    "                text=text.replace(p1,p2)\n",
    "            if \"bc\" not in text:\n",
    "                text=text.replace(\"c\",\"\")\n",
    "            else: \n",
    "                pos=text.index(\"c\")\n",
    "                # print(\"pos\",pos)\n",
    "                if pos!=0 and text[pos-1:pos+1]!=\"bc\":\n",
    "                    text=text[pos+1:]\n",
    "                elif pos==0:\n",
    "                    text=text[pos+1:]\n",
    "                # print(text)\n",
    "\n",
    "            for i in [\"[\",\"]\",\".\",\";\",\":\",\"\\t\",\"&\",'\"',\"(\",\")\",\"'\",\"#\",\"%\",\"$\",\"@\",\"*\",\"^\",\"=\",\"+\",\"{\",\"}\",\"?\",\"!\",\"~\",\"`\",\"<unauthorised>\",\"<i>\",\"<\\i>\",\"<aat>\"]:\n",
    "                text=text.replace(i,\"\")\n",
    "            for p1,p2 in [(\"//\",\"/\"),(\"rd\",\"th\"),(\"nd\",\"th\"),(\"st\",\"th\"),(\" \",\"\"),(\" - \",\"-\"),(\"th\",\"00\"),(\"ad\",\"\"),(\"ac\",\"\"),(\"s\",\"\"),(\"to\",\"-\"),(\"ce\",\"\")]:\n",
    "                text=text.replace(p1,p2)\n",
    "            \n",
    "            if \"/\" in text:\n",
    "                if text.count(\"/\")==4:\n",
    "                    text=text[6:10]+\"-\"+text[-4:]\n",
    "                elif text.count(\"/\")==2:\n",
    "                    elems=text.split(\"/\")\n",
    "                    # print(\"elems\",elems,elems[1],len(elems[1]))\n",
    "                    if len(elems[1])==3:\n",
    "                        # print(\"text\",text)\n",
    "                        # text=text.replace(\" \",\"\")\n",
    "                        text=elems[2].replace(\" \",\"\")+\"-\"\n",
    "                    elif \"-\" not in elems[1]:\n",
    "                        text=text[6:10]+\"-\"+text[-4:]\n",
    "                    else:\n",
    "                        text=text[3:7]+\"-\"+text[-4:]\n",
    "                else:\n",
    "                    text=text.replace(\"/\",\"\")\n",
    "                \n",
    "            if \"th\" not in text:\n",
    "                if len(text)==4:\n",
    "                    text+=\"-\"\n",
    "\n",
    "            if text[0]==\"-\":\n",
    "                new_text=\"_\"+text[1:]\n",
    "                text=new_text\n",
    "            # print(text)\n",
    "            text=text.replace(\"--\",\"-_\")\n",
    "            # copy_text=text\n",
    "            # text=text.replace(\"_\",\"\")\n",
    "\n",
    "            # print(\"text\",text)\n",
    "            if text.count(\"-\")>1:\n",
    "                text=text[-4:]\n",
    "\n",
    "            if text==\"\" or text==\" \":\n",
    "                text=\"unknown\"\n",
    "                set_text=set([text])\n",
    "                return set_text\n",
    "            \n",
    "\n",
    "            if \"-\" in text:\n",
    "                text=text.replace(\" \",\"\")\n",
    "                elems=text.split(\"-\")\n",
    "                new_elems=[]\n",
    "                # print(elems)\n",
    "                # new_text=\"\"\n",
    "                if len(elems)==2 and elems[1]!=\"\" and elems[1]!=\" \":\n",
    "                    if len(elems[0])==4 and len(elems[1])<3:\n",
    "                        # print(\"elems\",elems[1])\n",
    "                        elems[1]=str(int(elems[0])//100*100+int(elems[1]))\n",
    "                        # print(elems[0],elems[1])\n",
    "                for i,e in enumerate(elems):\n",
    "                    # sign_e=e[0]\n",
    "                    # print(e)\n",
    "                    if \"bc\" in e:\n",
    "                        e=\"_\"+e.replace(\" \",\"\").replace(\"bc\",\"\")\n",
    "                        elems[i]=e\n",
    "\n",
    "\n",
    "                    e=e.replace(\"_\",\"\")\n",
    "                    try:\n",
    "                        if len(elems)==2:\n",
    "                            # print(elems,elems[1],\"da\",e)\n",
    "                            if e!=\"\":\n",
    "                                # print(\"e\",e)\n",
    "                                ie=int(e)\n",
    "                                # print(ie)\n",
    "                                if len(e)>1 and len(e)<5:\n",
    "                                    ie=ie//100+1\n",
    "                                    #print(ie)\n",
    "                                    if len(new_elems)>0 and (str(ie)+\"th\")!=new_elems[0]:\n",
    "                                        new_elems.append(str(ie)+\"th\")\n",
    "                                        # print(\"aici\",ie,new_elems[0])\n",
    "                                    if len(new_elems)==0:\n",
    "                                        new_elems.append(str(ie)+\"th\")\n",
    "                                        # print(\"acolo\")\n",
    "                    except:\n",
    "                        # print(\"except?\", original_text,\";\", text, elems,new_elems)\n",
    "                        # print(ie)\n",
    "                        return set([\"unknown\"])\n",
    "                        if e !=\"\":\n",
    "                            new_elems.append(e)\n",
    "                for i in range(len(new_elems)):\n",
    "                    sign_e=elems[i][0]\n",
    "                    e=new_elems[i]\n",
    "                    if sign_e==\"_\":\n",
    "                        new_elems[i]=new_elems[i].replace(\"th\",\"thbc\")\n",
    "                    else:\n",
    "                        new_elems[i]=new_elems[i].replace(\"th\",\"thac\")\n",
    "\n",
    "\n",
    "                if len(new_elems)>1:\n",
    "                    text=new_elems[0]+\"-\"+new_elems[1]\n",
    "                else:\n",
    "                    text=new_elems[0]\n",
    "\n",
    "                for p1,p2 in [(\"3rd\",\"3th\"),(\"2nd\",\"2th\"),(\"1st\",\"1th\")]:\n",
    "                    text=text.replace(p2,p1)\n",
    "\n",
    "                if text==\"\" or text==\" \":\n",
    "                    text=\"unknown\"\n",
    "\n",
    "                if \"ac\" not in text and \"bc\" not in text and text!=\"pre-historic\" and text!=\"ironage\":\n",
    "                    text=\"unknown\"\n",
    "                set_text=set([text])\n",
    "            else:\n",
    "                if \"ac\" not in text and \"bc\" not in text and text!=\"pre-historic\" and text!=\"ironage\":\n",
    "                    text=\"unknown\"\n",
    "                set_text=set([text])\n",
    "            return set_text\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            text=text.lower()\n",
    "            re.sub(\"\\(\\w*\\)\",\"\",text)\n",
    "            re.sub(\"<\\w*>\",\"\",text)\n",
    "            re.sub(\"</.*>\",\"\",text)\n",
    "            re.sub(\"[3-9][0-9][0-9][0-9]\",\"\",text)\n",
    "            \n",
    "            \n",
    "            text=text.replace(\"thearly\",\"th\")\n",
    "\n",
    "            \n",
    "            for i in [\"[\",\"]\",\".\",\";\",\":\",\"\\t\",\"&\",'\"',\"(\",\")\",\"'\",\"#\",\"%\",\"$\",\"@\",\"*\",\"^\",\"=\",\"+\",\"{\",\"}\",\"/\",\"?\",\"!\",\"~\",\"`\",\"<unauthorised>\",\"<i>\",\"<\\i>\",\"<aat>\"]:\n",
    "                text=text.replace(i,\"\")\n",
    "            text=text.replace(\"thearly\",\"th\")\n",
    "            re.sub(\"\\(\\w*\\)\",\"\",text)\n",
    "            re.sub(\"<\\w\\w*>\",\"\",text)\n",
    "            re.sub(\"</.*>\",\"\",text)\n",
    "            re.sub(\"[3-9][0-9][0-9][0-9]\",\"\",text)\n",
    "            \n",
    "            set_text=set()\n",
    "            elems=text.split(\" \")\n",
    "            \n",
    "\n",
    "            if text==\"\":\n",
    "                return set()\n",
    "            #if \" \" in text:\n",
    "            for i in elems:\n",
    "                if i not in [\"and\",\"to\",\"the\",\"of\",\"by\",\"as\",\"a\"] and i!=\"\":\n",
    "                    if i != \"-\":\n",
    "                        ok=1\n",
    "                        for c in range(10):\n",
    "                            if str(c) in i:\n",
    "                                for term in [\"th\",\"st\",\"nd\",\"rd\",\"D\"]:\n",
    "                                    if term not in i:\n",
    "                                        if len(i)<4:\n",
    "                                            ok=0\n",
    "                        if ok:\n",
    "                            set_text.add(i)\n",
    "                            \n",
    "\n",
    "            # else:\n",
    "            #     set_text=set([text])\n",
    "            if not text:\n",
    "                return set([\"unknown\"])\n",
    "            return set_text\n",
    "    except:\n",
    "        # print(\"PROBLEM:\", original_text,\";\",text) \n",
    "        set_text=set([original_text])\n",
    "        # return set_text  \n",
    "        return set([\"unknown\"])\n",
    "        # return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_dict=brit_df\n",
    "classifiable_va=classifiable_brit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brit_df.at[0,\"image_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,i in enumerate(brit_df[\"image_path\"]):\n",
    "    print(j,i)\n",
    "    print(j,brit_df[\"image_path\"][j])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112611\n"
     ]
    }
   ],
   "source": [
    "print(len(brit_df[\"image_code\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_dict={}\n",
    "# print(brit_df.keys())\n",
    "for i in brit_df[\"image_code\"]:\n",
    "    va_dict[i]={}\n",
    "for val in brit_df:\n",
    "    # print(brit_df[i])\n",
    "    # print(j,val,i)\n",
    "    # print(\"jnul\",j,val,brit_df.at[j,val])\n",
    "    if val!=\"my_code\" and val!=\"image_code\":\n",
    "        for j,i in enumerate(brit_df[val]):\n",
    "            va_dict[brit_df.at[j,\"image_code\"]][val]=str(i)\n",
    "        # print(\"here\",i,va_dict[i][val])\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_keys_values={}\n",
    "va_keys_values2={}\n",
    "for k in classifiable_va:\n",
    "    va_keys_values[k]=set()\n",
    "for k in va_dict:\n",
    "    for cls in va_dict[k]:\n",
    "        va_keys_values2[cls]={}\n",
    "    break\n",
    "for k in va_dict:\n",
    "    for cls in va_dict[k]:\n",
    "        va_keys_values2[cls][k]=set()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#2869 were too hard to parse - I put them as unknown\n",
    "all_results={}\n",
    "all_results_key={}\n",
    "\n",
    "count=0\n",
    "for k in va_dict:\n",
    "    for cls in va_dict[k]:\n",
    "        all_results[cls]={}\n",
    "    break\n",
    "for k in va_dict:\n",
    "    all_results_key[k]={}\n",
    "for k in va_dict:\n",
    "    for cls in va_dict[k]:\n",
    "        # all_results[cls]=[]\n",
    "        all_results_key[k][cls]={}\n",
    "        if cls in classifiable_va:\n",
    "            elems=va_dict[k][cls].replace(\"/n\",\"\").replace(\" ,\",\",\").replace(\", \",\",\").split(\",\")\n",
    "            for elem in elems:\n",
    "                if elem!=\"\":\n",
    "                    res=process(elem,cls)\n",
    "                    # if cls==\"productionDates\":\n",
    "                    if res!=0:\n",
    "                        all_results[cls][elem]=res\n",
    "                        va_keys_values[cls].update(res)\n",
    "                        va_keys_values2[cls][k].update(res)\n",
    "                        # all_results_key[k][cls][elem]=res\n",
    "                    else:\n",
    "                        count+=1\n",
    "                elif len(elems)==1:\n",
    "                    all_results[cls][elem]=set([\"unknown\"])\n",
    "                    va_keys_values2[cls][k].update(set([\"unknown\"]))\n",
    "                    # all_results_key[k][cls][elem]=set([\"unknown\"])\n",
    "\n",
    "        else:\n",
    "            elems=va_dict[k][cls].replace(\"/n\",\"\").replace(\" ,\",\",\").replace(\", \",\",\").split(\",\")\n",
    "            for elem in elems:\n",
    "                if elem!=\"\":\n",
    "                    all_results[cls][elem]=set([elem])\n",
    "                    all_results_key[k][cls][elem]=set([elem])\n",
    "                    va_keys_values2[cls][k].update(set([elem]))\n",
    "                elif len(elems)==1:\n",
    "                    all_results[cls][elem]=set([\"unknown\"])\n",
    "                    all_results_key[k][cls][elem]=set([\"unknown\"])\n",
    "                    va_keys_values2[cls][k].update(set([\"unknown\"]))\n",
    "                # va_keys_values[cls][elem]=all_results[cls][elem]\n",
    "                \n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create eval zeroshot csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['key', 'image_path', 'caption'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"/home/username/open_clip/finetuning/val12.csv\")\n",
    "df2 = pd.read_csv(\"/home/username/open_clip/finetuning/train12.csv\")\n",
    "\n",
    "# va_images=df1[df1[\"image_path\"]>=\"/scratch/username/data/va_images/\"]\n",
    "\n",
    "print(df1.keys())\n",
    "old_info={\"key\":[],\"image_path\":[],\"caption\":[]}\n",
    "images_paths=[]\n",
    "captions=[]\n",
    "for i in range(len(list(df1[\"image_path\"]))):\n",
    "    old_info[\"key\"].append(df1[\"key\"][i])\n",
    "    old_info[\"image_path\"].append(df1[\"image_path\"][i])\n",
    "    old_info[\"caption\"].append(df1[\"caption\"][i])\n",
    "for i in range(len(list(df2[\"image_path\"]))):\n",
    "    old_info[\"key\"].append(df2[\"key\"][i])\n",
    "    old_info[\"image_path\"].append(df2[\"image_path\"][i])\n",
    "    old_info[\"caption\"].append(df2[\"caption\"][i])\n",
    "\n",
    "old_info_df=pd.DataFrame(old_info)\n",
    "old_info=old_info_df[old_info_df[\"image_path\"]<\"/scratch/username/data/va_images/\"]\n",
    "# print(\"va_image\" in df1[\"image_path\"][1])\n",
    "# print(\"va_image\" in df1['image_path'])\n",
    "# print(old_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88581\n",
      "106611\n",
      "5687\n"
     ]
    }
   ],
   "source": [
    "print(len(old_info[\"key\"]))\n",
    "print(len(va_keys_values2[\"image_path\"]))\n",
    "print(len(britmus_images[\"key\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_classes={}\n",
    "classes_to_id={}\n",
    "\n",
    "classes_ids={}\n",
    "for k in all_results_key:\n",
    "    for cls in all_results_key[k]:\n",
    "        json_classes[cls]={}\n",
    "        classes_ids[cls]=0\n",
    "        classes_to_id[cls]={}\n",
    "    break\n",
    "\n",
    "\n",
    "# va_keys_values2[cls][k]\n",
    "for cls in va_keys_values2:\n",
    "        for k in va_keys_values2[cls]:\n",
    "            elem=va_keys_values2[cls][k]\n",
    "            for e in elem:\n",
    "                e=str(e).replace(\"'\",\"\").replace('\"',\"\").replace(\"\\\\r\",\"\").replace(\"\\\\n\",\"\").replace(\"\\\\t\",\"\").lower()\n",
    "                if e not in classes_to_id[cls]:\n",
    "                    idx=classes_ids[cls]\n",
    "                    idx+=1\n",
    "                    json_classes[cls][idx]=e\n",
    "                    classes_to_id[cls][json_classes[cls][idx]]=idx\n",
    "                    classes_ids[cls]=idx\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"/home/username/open_clip/finetuning/b_classes_new.json\",\"w\") as f:\n",
    "#     json.dump(json_classes,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"024289_2007-6001-8039.jpg\" in va_keys_values2[\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path\n",
      "caption\n",
      "Museum number\n",
      "Subjects\n",
      "Curators Comments\n",
      "Inscription\n",
      "Technique\n",
      "Materials\n",
      "Production place\n",
      "Production date\n",
      "Assoc name\n",
      "Culture\n",
      "Object type\n",
      "Producer name\n",
      "School/style\n",
      "Title\n"
     ]
    }
   ],
   "source": [
    "for cls in va_keys_values2:\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#verifica daca all_results si keys sunt in aceeasi ordine\n",
    "new_df=old_info.copy()\n",
    "bad=[]\n",
    "count=0\n",
    "\n",
    "for cls in va_keys_values2:\n",
    "    new_list=[]\n",
    "    if cls == 'image_path' or cls == 'caption': continue\n",
    "    for k in old_info[\"key\"]:\n",
    "        list1=[]\n",
    "        # print(cls,k)\n",
    "        elem=va_keys_values2[cls][k]\n",
    "        for e in elem:\n",
    "            e=str(e).replace(\"'\",\"\").replace('\"',\"\").replace(\"\\\\r\",\"\").replace(\"\\\\n\",\"\").replace(\"\\\\t\",\"\").lower()\n",
    "            if e in classes_to_id[cls]:\n",
    "                list1.append(classes_to_id[cls][e])\n",
    "            else:\n",
    "                print(e,k,cls,elem)\n",
    "                bad.append(e)\n",
    "                exit(0)\n",
    "        new_list.append(list1)\n",
    "    new_df[cls]=new_list\n",
    "        \n",
    "\n",
    "\n",
    "print(len(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_info_df=pd.DataFrame()\n",
    "new_info=old_info_df[new_df[\"image_path\"]<\"/scratch/username/data/va_images/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('/home/username/open_clip/finetuning/train_brit_classes_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('/home/username/open_clip/finetuning/val_brit_classes_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get britmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "va_path='/home/username/open_clip/finetuning/all_brit_classes_new.csv'\n",
    "brit_df = pd.read_csv(va_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "britmus_train=brit_df[brit_df[\"key\"].isin(df[\"key\"])]\n",
    "britmus_val=brit_df[brit_df[\"key\"].isin(df2[\"key\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       5677, 5678, 5679, 5680, 5681, 5682, 5683, 5684, 5685, 5686],\n",
      "      dtype='int64', length=5687)\n",
      "Index([ 5687,  5688,  5689,  5690,  5691,  5692,  5693,  5694,  5695,  5696,\n",
      "       ...\n",
      "       88571, 88572, 88573, 88574, 88575, 88576, 88577, 88578, 88579, 88580],\n",
      "      dtype='int64', length=82894)\n"
     ]
    }
   ],
   "source": [
    "print(britmus_val[\"key\"].keys())\n",
    "print(britmus_train[\"key\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# britmus_train.to_csv('/home/username/open_clip/finetuning/train_brit_dataset_new.csv',index=False)\n",
    "# britmus_val.to_csv('/home/username/open_clip/finetuning/val_brit_dataset_new.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
